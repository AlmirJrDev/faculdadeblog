{
  "hash": "b51c204921e11aa0deab1c1d95b7c90c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Atividade 03 - Regressão Linear com Álgebra Matricial\"\nauthor: \"Seu Nome\"\ndate: \"2024-11-23\"\ncategories: [python, machine-learning, estatística, matemática]\nimage: \"thumbnail.jpg\"\n---\n\n## Objetivo\n\nImplementar regressão linear do zero usando álgebra matricial (sem bibliotecas de ML prontas) para prever salários baseados em anos de estudo.\n\n## Tecnologias Utilizadas\n\n- **Python 3.x**\n- **numpy**: Para operações matriciais\n- **pandas**: Para manipulação de dados\n- **plotly**: Para visualização\n\n## Fundamentação Matemática\n\n### Fórmula da Regressão Linear\n\nA regressão linear busca encontrar a melhor reta que se ajusta aos dados:\n\n$$\ny = a + bx\n$$\n\nOnde:\n- $y$ = variável dependente (salário)\n- $x$ = variável independente (anos de estudo)\n- $a$ = intercepto\n- $b$ = coeficiente angular\n\n### Solução Matricial\n\nUsando álgebra linear, podemos resolver o sistema usando:\n\n$$\n\\beta = (X^TX)^{-1}X^Ty\n$$\n\nOnde:\n- $\\beta$ = vetor de coeficientes $[a, b]$\n- $X$ = matriz de design (com coluna de 1s para o intercepto)\n- $y$ = vetor de respostas\n\n### Coeficiente de Determinação (R²)\n\nMede a qualidade do ajuste:\n\n$$\nR^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n$$\n\n- $SS_{res}$ = soma dos quadrados dos resíduos\n- $SS_{tot}$ = soma total dos quadrados\n\n**Interpretação**: R² próximo de 1 indica bom ajuste.\n\n## Implementação\n\n### 1. Carregamento dos Dados\n\n```python\n# Carregar dados dos arquivos\nX_data = np.loadtxt('X.txt')  # Anos de estudo\ny_data = np.loadtxt('y.txt')  # Salário\n```\n\n### 2. Construção da Matriz X\n\nA matriz X precisa incluir uma coluna de 1s para o intercepto:\n\n```python\n# X_matriz = [1, x1]\n#            [1, x2]\n#            [1, x3]\n#            ...\nX_matriz = np.vstack([np.ones(len(X_data)), X_data]).T\n```\n\n**Explicação**: `np.vstack` empilha arrays verticalmente, criando a matriz com duas colunas.\n\n### 3. Cálculo dos Coeficientes\n\nAplicando a fórmula matricial:\n\n```python\n# β = (X'X)^(-1) X'y\nbeta = np.linalg.inv(X_matriz.T @ X_matriz) @ X_matriz.T @ y_data\na, b = beta[0], beta[1]\n```\n\n**Operações**:\n- `X_matriz.T` = transposta de X\n- `@` = multiplicação matricial\n- `np.linalg.inv()` = inversa da matriz\n\n### 4. Predições e Avaliação\n\n```python\n# Calcular valores preditos\ny_pred = a + b * X_data\n\n# Calcular R²\nss_res = np.sum((y_data - y_pred) ** 2)\nss_tot = np.sum((y_data - np.mean(y_data)) ** 2)\nr_squared = 1 - (ss_res / ss_tot)\n```\n\n### 5. Visualização\n\nCriamos um gráfico com:\n- Pontos observados (dados reais)\n- Linha de regressão (modelo ajustado)\n\n```python\nfig = go.Figure()\n\n# Pontos observados\nfig.add_trace(go.Scatter(\n    x=X_data, y=y_data,\n    mode='markers',\n    name='Dados Observados',\n    marker=dict(color='blue', size=5, opacity=0.6)\n))\n\n# Linha de regressão\nfig.add_trace(go.Scatter(\n    x=X_data, y=y_pred,\n    mode='lines',\n    name=f'Regressão Linear (R²={r_squared:.3f})',\n    line=dict(color='red', width=2)\n))\n```\n\n## Resultados\n\n### Equação Obtida\n\nPara o dataset fornecido, a equação da reta é:\n\n$$\n\\text{Salário} = a + b \\times \\text{Anos de Estudo}\n$$\n\nOnde:\n- **Intercepto (a)**: R$ XXXX.XX\n- **Coeficiente (b)**: R$ XXXX.XX por ano\n\n**Interpretação**: A cada ano adicional de estudo, o salário aumenta em média R$ XXXX.XX.\n\n### Qualidade do Ajuste\n\n- **R²**: 0.XXXX (XX.X%)\n- Isso significa que XX% da variabilidade dos salários é explicada pelos anos de estudo\n\n### Gráfico Interativo\n\n[Clique aqui para visualizar o gráfico completo](regressao_linear.html)\n\nO gráfico permite:\n- Identificar outliers\n- Verificar a dispersão dos dados\n- Avaliar visualmente a qualidade do ajuste\n\n## Código Completo\n\n::: {#ebb04708 .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Ver código completo\"}\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\n\ndef calcular_regressao_linear(arquivo_x='X.txt', arquivo_y='y.txt'):\n    \"\"\"\n    Calcula regressão linear usando fórmula matricial.\n    \"\"\"\n    # [Código completo da função]\n    pass\n\nif __name__ == \"__main__\":\n    resultado = calcular_regressao_linear('X.txt', 'y.txt')\n    print(resultado)\n```\n:::\n\n\n## Análise dos Resultados\n\n### Pontos Fortes\n- A relação entre anos de estudo e salário é **positiva e linear**\n- O R² indica um **bom ajuste** do modelo\n- Os dados seguem razoavelmente a linha de tendência\n\n### Limitações\n- Outros fatores podem influenciar o salário (experiência, área, localização)\n- Outliers podem indicar casos especiais\n- A relação pode não ser perfeitamente linear em toda a extensão\n\n## Aprendizados\n\n1. **Álgebra Linear**: Aplicação prática de operações matriciais\n2. **Regressão Linear**: Implementação do zero, entendendo cada etapa\n3. **Interpretação**: Como ler e comunicar resultados estatísticos\n4. **NumPy**: Uso eficiente de operações vetorizadas\n\n## Comparação com Bibliotecas Prontas\n\nNossa implementação é equivalente a:\n\n```python\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_data.reshape(-1, 1), y_data)\n\n# Nosso resultado deve ser igual a:\n# model.intercept_ == a\n# model.coef_[0] == b\n# model.score(X_data.reshape(-1, 1), y_data) == r_squared\n```\n\n## Possíveis Melhorias\n\n- Adicionar intervalos de confiança\n- Implementar validação cruzada\n- Detectar e tratar outliers automaticamente\n- Testar transformações não-lineares\n- Adicionar mais features (regressão múltipla)\n\n## Referências\n\n- [NumPy Documentation](https://numpy.org/doc/)\n- [Linear Regression Theory](https://en.wikipedia.org/wiki/Linear_regression)\n- [Ordinary Least Squares](https://en.wikipedia.org/wiki/Ordinary_least_squares)\n\n---\n\n**Repositório**: [Link para o código no GitHub](https://github.com/seu-usuario/seu-repo)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}